---
title: 'From Messy to Tidy: Gather All Those Dates'
author: Recle Etino Vibal
date: '2018-10-03'
categories:
  - lessons
  - Philippines
  - tidyverse
  -tidy data
tags:
  - consumer price index
  - dplyr
  - lubridate
  - tidyr
slug: messy-tidy-tidyr-gather
output:
  blogdown::html_page:
    toc: yes
    number_sections: true
bibliography:
  - references/messy-to-tidy.bib
biblio-style: apalike
---

```{r packages-opts, message=FALSE, warning=FALSE, include=FALSE}

# Attach packages and set chunk options

library(knitr)
library(tidyverse)
library(magrittr)
library(lubridate)
library(DT)
library(rebus)

opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  echo = FALSE
)

```

# Tidy Data: Long But Machine Readable

Working with data made me concious of how we compile, store, and share data. Most of us work with spreadsheets and most of the time we encode our data in a way that makes it easy for other people to read our data. Unfortunately, human readable data format is not necessarily machine readable data. When we want to work with data in code, human readable data is not usually the best form to begin with and to share with other people who wants to reproduce our work.

@tidy-data has the following definition of a [tidy data](http://vita.had.co.nz/papers/tidy-data.html):


>Data is tidy when 
>
>1. Every column is a variable, 
>2. Every row is an observation, and 
>3. Every observational unit forms a table.

Data that is not tidy is *messy*.

@share-data also advocates tidy data principles and good practices when [sharing data](https://peerj.com/preprints/3139/) for collaboration.

I wanted to discuss these three properties in the context of a real world data in one post, but the data I will work with is quite messy, not the messiest I have seen, but messy enough for me to work on a lot of things. This post will be the first post in the "From Messy to Tidy" series.

# Consumer Price Index of the Philippines

```{r read-cpi-data}

# Read CPI Data

raw_cpi_data <- 
  readr::read_csv(
    "./data/ph-cpi-data/raw/CPI_2006=100_1994-2018_1_2.csv",
    trim_ws = TRUE
  )

```

The data I will use here is the Philippines consumer price index from 1994 Jan to 2018 Jun retrieved [here](http://openstat.psa.gov.ph/dataset/prices-and-related-indices) on 2018 Sep 28.

```{r show-raw-data-sample, fig.cap="First Twenty Rows of the Philippines Monthly Consumer Price Index (CPI) for All Income Households by Commodity Group and Geographic Area from 1994 Jan to 2018 Jun. CPI from 1994 to 2005 are the equivalent/estimated 2006-based CPI using the splicing method. Data from Philippine Statistics Authority (http://openstat.psa.gov.ph)."}

# Show Sample of CPI Data

raw_cpi_data %>% 
  head(20) %>% 
  DT::datatable(
    extensions = 'FixedColumns',
    options = list(
      scrollX = TRUE,
      scrollCollapse = TRUE
    )
  )

```

According to the [Philippine Statistics Authority](http://openstat.psa.gov.ph/)

> Consumer Price Index (CPI) - is an indicator of the change in the average retail prices of a fixed basket of goods and services commonly purchased by households relative to a base year.CPI stands for the percentage change in the average prices of goods and services commonly bought by a group of consumers from the base year.

The initial reason why I looked at this data was because of the high inflation rates the Philippines is experiencing in 2018. However, after I saw how the data looked, I became more interested in using it to discuss tidy data principles and ways to turn a data set from messy to tidy.

# Messy Data Cues

Usually tidy data takes the form of a long table. This is just a consequence of keeping variables in columns and observations in rows. A wide table, like Table \@ref(fig:show-raw-data-sample), is a common cue that a data is not tidy. The CPI data has `r ncol(raw_cpi_data)` columns and `r nrow(raw_cpi_data) %>% scales::comma()` rows. The dimensions may indicate a long table already, but we must further investigate; `r ncol(raw_cpi_data)` columns is just too many to be just variables.

## Dates as Columns

One of the common ways of making a data set messy is by creating columns that are not variables but values of a certain observation, which happens quite often with dates in the wild. In the CPI data, there are `r colnames(raw_cpi_data) %>% str_detect(paste(month.abb %R% "_" %R% one_or_more(DGT), collapse = "|")) %>% sum()` columns that are month and year data, not even in [ISO 8601](https://en.wikipedia.org/wiki/ISO_8601) format (YYYY-MM-DD). Under each date column is supposed the consumer price index. Variables under variables are not the tidy way.

## Average Columns

Before I do something about these dates, I also noticed that there are `Ave_yy` columns. These columns show the average CPI for each year. 

@share-data considers raw data in the correct format if it **did not**

1. Ran on software
2. Modify data
3. Remove data
4. Summarise data

I can only assume that the first three conditions was followed. There are missing values, but I think it was missing in the first place rather than removed. I am sure that the `Ave_yy` summarises the data. Manipulating data to obtain any statistical value like the average is easy for any data analyst to do when the raw data is tidy or at least near tidy. Having summary columns are not only unnecessary, but it also may lead the data analyst into checking what these columns mean^[I wanted to verify if the `Ave_yy` columns are really the average of the CPI for each year. However, I think I was dwelling on it too much rather than focus on tidying the data. My experience with `Ave_yy` columns just proves that summaries only hinder the data analysis]. From the definition of CPI, I also don't think that the annual average is a necessary and correct value to consider.

# Short Steps to a Long Table

For this post, I have the following tasks:

1. Remove the `Ave_yy` columns,
2. Collect all the `month_year` and CPI values underneath into separate columns, and
3. COnvert the new date columns in ISO 8601 format^[@share-data also advocates ISO 8601 as the preffered date format for consistency and because the YYYY-MM-DD format is not misconstrued in Excel. I agree with them. For more variable coding guidelines, see Figure 2 of @share-data].

I opted at separating the code and the discussion of my process such that the discussion will not be interrupted by code blocks and such that the reader can review my process through code in one uninterrupted pass after reading my discussion. For all the packages and code I used, please refer to \@ref(code)

## Remove Columns with Names that Starts with the Same Characters

`dplyr::select()` [@R-dplyr] allows for selecting or removing columns by column names. There are `r raw_cpi_data %>% colnames() %>% str_detect("Ave") %>% sum()` `Ave_yy` columns. Listing them one-by-one is bothersome.

`dplyr::starts_with()` [@R-dplyr] to the rescue. As the function name implies, `dplyr::starts_with()` selects all column names that begin with the specified string. We can remove `r raw_cpi_data %>% colnames() %>% str_detect("Ave") %>% sum()` `Ave_yy` columns using two simple functions. Just don't forget the `-` to tell select that we want the columns removed not selected. I also removed the extra `X324` column.

```{r remove-ave-cols}

# Remove the Ave_yy columns

no_ave_cpi_data <- 
  raw_cpi_data %>% 
  select(-starts_with("Ave"), -X324)

```

## Gather the Date Columns

Converting a table from wide to long format is possible with `tidyr::gather()` [@R-tidyr]. It takes four important arguments: the wide `data`, the `key` or column name we want to call the the column names we are gathering, the `value` or the column name we want to call the variables under the columns we will collect, and `...` or the set of column names we want to gather.

Since the column names we want to gather the `month_year`, it is appropriate to call the "key" column "month_year". The values under the `month_year` columns are the CPI for each month; the appropriate "value" column is "cpi".

There are `r colnames(raw_cpi_data) %>% str_detect(paste(month.abb %R% "_" %R% one_or_more(DGT), collapse = "|")) %>% sum()` `month_year` columns, so listing them one-by-one is more bothersome than listing the `Ave_yy` columns. `dplyr::starts_with()` will not help us here because it needs a specific string to match as prefix. The `month_year` columns have different beginnings (i.e. `r knitr::combine_words(month.abb)`). In situations like this, we will need the help of `dplyr::matches()` [@R-dplyr]. The advantage of `dplyr::matches()` over `dplyr::starts_with()` is that finds column names that matches a regular expression anywhere in the column name.

The mention of regular expressions might have disturbed the balance of the universe, but nothing to worry, `{rebus`} [@R-rebus] to the rescue. With the `month.abb` (built-in vector of three-letter abbreviations of English month names) and `paste()`, we can create the regex expression to select all the `month_year` columns with `paste(month.abb %R% "_" %R% DGT %R% DGT, collapes = "|")`^[For those who want to use regular expressions, the equivalent is `Jan_\\d\\d|Feb_\\d\\d|Mar_\\d\\d|Apr_\\d\\d|May_\\d\\d|Jun_\\d\\d|Jul_\\d\\d|Aug_\\d\\d|Sep_\\d\\d|Oct_\\d\\d|Nov_\\d\\d|Dec_\\d\\d`]. I used `collapse = "|"` because `dplyr::matches()` only takes one regular expression as argument and `|` is interpreted as the "or"" separator.

```{r gather-month-year}

# Gather the month_year columns

long_cpi_data <- 
  no_ave_cpi_data %>% 
  gather(
    month_year,
    cpi,
    matches(paste(month.abb %R% "_" %R% DGT %R% DGT, collapse = "|"))
  )

```

Here is the sample of what we have done so far.

```{r show-gathered-cpi-data, fig.cap="The Data so Far. No Ave_yy Columns and month_year Columns Gathered in One Column."}

# Show CPI data after gathering, so far

long_cpi_data %>%
  head(20) %>% 
  DT::datatable(
    extensions = 'FixedColumns',
    options = list(
      scrollX = TRUE,
      scrollCollapse = TRUE
    )
  )

```

Looking good so far. The data went from wide (`r paste(ncol(raw_cpi_data), "rows by", nrow(raw_cpi_data) %>% scales::comma(), "columns")`) to long (`r paste(ncol(long_cpi_data), "rows by", nrow(long_cpi_data) %>% scales::comma(), "columns")`) in just a few lines of code. However, the `month_year` column is still not in ISO 8601 format. The next step will be tricky.

## Convert to YYYY-MM-DD

Years in the CPI data are abbreviated to only the last two digits of the year. This makes it very difficult for future encoding of data. What happens when the data goes beyond 2094 or if we obtained data since 1800? This another reason why ISO 8601 format is prefferable, there is no confusion about the year because it is spelled out. However, this is why we are tidying the data, so that future data analysts and gatherers can update the data with consistency and ease. 

To manipulate the two-digit years, I first split the `month_year` column to `month` and `year` using `tidyr::separate()` [@R-tidyr]. With the two-digit `year` column, I added 1900 when years are in the 90s and 2000 otherwise. I work on dates with `{lubridate}` [@R-lubridate]. A "YYYY-MM-DD" string can be converted to a YYYY-MM-DD date with `lubridate::ymd()`. Since the original CPI data only had months and year, and we can assume that this is end of months CPI values, I had to arbitrarily add a day field. I used 1 because all months begin with 1; months end at different days then there is also the leap year. My initial date is `ymd(paste(year, month, 1, sep = "-"))`. To convert this to end-of-month dates, I used `lubridate::ceiling_date()`, specifying `unit = "month"` for rounding-up in by month. However, `lubridate::ceiling_date()` rounds up a month to the first day of the next month (See the `?lubridate::ceiling_date()` for more information). To obtain the real end-of-month date, I had to subtract a period of 1 day using `lubridate::days(1)`.

```{r convert-iso-8601}

# Convert month_year column into ISO 8601 date column

iso_8601_cpi_data <- 
  long_cpi_data %>% 
  # Split month and year values
  separate(
    month_year,
    into = c("month", "year")
  ) %>% 
  mutate(
    # Convert year to numeric
    year = as.numeric(year),
    # Add 1900 to 90s and 2000 to 2k years
    year = if_else(
      year > 93,
      year + 1900,
      year + 2000
    ),
    # Combine date values and convert to YYYY-MM-DD format; use start of month first
    date_cpi = ymd(
      paste(year, month, 1, sep = "-")
    ),
    # Change to end of month
    date_cpi = ceiling_date(date_cpi, unit = "month") - days(1)
  ) %>% 
  # remove the month and year columns
  select(-month, -year)

```

Converting to ISO 8601 looks easier in code, but it was a tricky process to get here when you are just thinking about to handle the messy data for the first time.

# Not Yet Tidy, A Little Less Messy

Here is the first twenty rows of the data so far. 

```{r show-iso-8601-data, fig.cap="Sample CPI Data after Converting Dates to ISO 8601 Format."}

# SHow data after converting dates to ISO 8601 format

iso_8601_cpi_data %>%
  head(20) %>% 
  DT::datatable(
    extensions = 'FixedColumns',
    options = list(
      scrollX = TRUE,
      scrollCollapse = TRUE
    )
  )

```

Observe that there are still more things to do before we can say that the Philippine CPI data is tidy, but this is enough for one post.

```{r save-partial-data}

saveRDS(iso_8601_cpi_data, "./data/ph-cpi-data/partial-tidy/iso_8601_cpi_data.RDS")

```

Up Next: What is that `Code` column?

# Code {#code}

The following codes show what I did in this post. The logic of each code should have been captured in the discussion. I added comments here and there to further clarify my thought process.

```{r all-codes, ref.label = all_labels(), echo=TRUE, eval=FALSE}

```

My session info for reproducibility.

```{r session-info}

sessionInfo()

```

# References

For more information tidy principles, techniques, and good practices, and the packages and functions I used in this post, please read




